## General Data Science pipeline
---

### 1. Define and understand the problem

The problem needs to be clearly defined and then turned into a Data Science task, so clear steps can be defined on how to solve it.

### 2. Data collection

In this step, it is important to collect the data that is suitable for the job. It is a good idea to collect more data than you need as data sets can be incomplete and dirty. Although, it is very important to highlight that the *quality* of the data is more important than the *quantity*.

### 3. Data cleaning and preprocessing

Raw data can include missing entries, duplicates, extreme outliers to name a few. Un- or improperly processed data will lead to bad models.

### 4. Data exploration (EDA)

In this phase—often referred to as *Exploratory Data Analysis*—characteristics of the dataset are summarized and visualized. It helps in understanding what the collected data tells us: answer questions right away, see patterns or anomalies that could guide in building a better model.

### 5. Model building

In this part, the preprocessed data is used to train a model that discoveres hidden patterns or learn from it in order to make predictions for the future.

### 6. Evaluation

### 7. Deployment and refinement
